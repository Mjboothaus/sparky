{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "from pyspark.sql import SparkSession\n",
    "import spark_df_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:25:32 WARN Utils: Your hostname, tmps-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 172.20.131.88 instead (on interface en0)\n",
      "22/09/26 12:25:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:25:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/26 12:25:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "session = SparkSession.builder.getOrCreate()\n",
    "ipsc = ibis.pyspark.connect(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df_rdd = session.read.csv(\"../data/sample_big_mortgage_file.csv.gz\", header=True, sep=\"|\")\n",
    "\n",
    "df_rdd = session.read.csv(\"../data/2020_lar.txt.gz\", header=True, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:25:45 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df_rdd.createTempView(\"tmp_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ibis.backends.pyspark.Backend at 0x12f114b80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.list_databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tmp_df_table']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.list_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table = ipsc.table(\"tmp_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derived_msa_md\n",
      "derived_loan_product_type\n",
      "derived_dwelling_category\n",
      "derived_ethnicity\n",
      "derived_race\n",
      "derived_sex\n",
      "discount_points\n",
      "debt_to_income_ratio\n",
      "denial_reason_1\n",
      "denial_reason_2\n",
      "denial_reason_3\n",
      "denial_reason_4\n"
     ]
    }
   ],
   "source": [
    "for col in my_table.columns:\n",
    "    if col[0] == \"d\":\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM tmp_df_table LIMIT 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT DISTINCT derived_sex FROM tmp_df_table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = session.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      derived_sex|\n",
      "+-----------------+\n",
      "|Sex Not Available|\n",
      "|           Female|\n",
      "|            Joint|\n",
      "|             Male|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25671238"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now the Ibis approach\n",
    "\n",
    "ibis.options.interactive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.current_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/zhl433ms1fx5rvtvcrkw6dgw0000gn/T/ipykernel_36085/3364586496.py:1: FutureWarning: `exists_table` is deprecated as of v2.0; use `name in client.list_tables()`\n",
      "  ipsc.exists_table(\"tmp_df_table\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.exists_table(\"tmp_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activity_year',\n",
       " 'lei',\n",
       " 'derived_msa_md',\n",
       " 'state_code',\n",
       " 'county_code',\n",
       " 'census_tract',\n",
       " 'conforming_loan_limit',\n",
       " 'derived_loan_product_type',\n",
       " 'derived_dwelling_category',\n",
       " 'derived_ethnicity',\n",
       " 'derived_race',\n",
       " 'derived_sex',\n",
       " 'action_taken',\n",
       " 'purchaser_type',\n",
       " 'preapproval',\n",
       " 'loan_type',\n",
       " 'loan_purpose',\n",
       " 'lien_status',\n",
       " 'reverse_mortgage',\n",
       " 'open_end_line_of_credit',\n",
       " 'business_or_commercial_purpose',\n",
       " 'loan_amount',\n",
       " 'combined_loan_to_value_ratio',\n",
       " 'interest_rate',\n",
       " 'rate_spread',\n",
       " 'hoepa_status',\n",
       " 'total_loan_costs',\n",
       " 'total_points_and_fees',\n",
       " 'origination_charges',\n",
       " 'discount_points',\n",
       " 'lender_credits',\n",
       " 'loan_term',\n",
       " 'prepayment_penalty_term',\n",
       " 'intro_rate_period',\n",
       " 'negative_amortization',\n",
       " 'interest_only_payment',\n",
       " 'balloon_payment',\n",
       " 'other_nonamortizing_features',\n",
       " 'property_value',\n",
       " 'construction_method',\n",
       " 'occupancy_type',\n",
       " 'manufactured_home_secured_property_type',\n",
       " 'manufactured_home_land_property_interest',\n",
       " 'total_units',\n",
       " 'multifamily_affordable_units',\n",
       " 'income',\n",
       " 'debt_to_income_ratio',\n",
       " 'applicant_credit_score_type',\n",
       " 'co_applicant_credit_score_type',\n",
       " 'applicant_ethnicity_1',\n",
       " 'applicant_ethnicity_2',\n",
       " 'applicant_ethnicity_3',\n",
       " 'applicant_ethnicity_4',\n",
       " 'applicant_ethnicity_5',\n",
       " 'co_applicant_ethnicity_1',\n",
       " 'co_applicant_ethnicity_2',\n",
       " 'co_applicant_ethnicity_3',\n",
       " 'co_applicant_ethnicity_4',\n",
       " 'co_applicant_ethnicity_5',\n",
       " 'applicant_ethnicity_observed',\n",
       " 'co_applicant_ethnicity_observed',\n",
       " 'applicant_race_1',\n",
       " 'applicant_race_2',\n",
       " 'applicant_race_3',\n",
       " 'applicant_race_4',\n",
       " 'applicant_race_5',\n",
       " 'co_applicant_race_1',\n",
       " 'co_applicant_race_2',\n",
       " 'co_applicant_race_3',\n",
       " 'co_applicant_race_4',\n",
       " 'co_applicant_race_5',\n",
       " 'applicant_race_observed',\n",
       " 'co_applicant_race_observed',\n",
       " 'applicant_sex',\n",
       " 'co_applicant_sex',\n",
       " 'applicant_sex_observed',\n",
       " 'co_applicant_sex_observed',\n",
       " 'applicant_age',\n",
       " 'co_applicant_age',\n",
       " 'applicant_age_above_62',\n",
       " 'co_applicant_age_above_62',\n",
       " 'submission_of_application',\n",
       " 'initially_payable_to_institution',\n",
       " 'aus_1',\n",
       " 'aus_2',\n",
       " 'aus_3',\n",
       " 'aus_4',\n",
       " 'aus_5',\n",
       " 'denial_reason_1',\n",
       " 'denial_reason_2',\n",
       " 'denial_reason_3',\n",
       " 'denial_reason_4',\n",
       " 'tract_population',\n",
       " 'tract_minority_population_percent',\n",
       " 'ffiec_msa_md_median_family_income',\n",
       " 'tract_to_msa_income_percentage',\n",
       " 'tract_owner_occupied_units',\n",
       " 'tract_one_to_four_family_homes',\n",
       " 'tract_median_age_of_housing_units']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.table(\"tmp_df_table\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ipsc.table(\"tmp_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = t.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25671238"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibis.show_sql(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_rdd.sample(fraction=0.1, seed=42).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rdd_cache = df_rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:35:28 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n",
      "22/09/26 12:35:28 WARN BlockManager: Persisting block rdd_79_0 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:48:59 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:49:00 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:49:11 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:49:23 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:408: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_constant_1d(df, column))\n",
      "[Stage 54:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:49:24 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:49:37 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:49:57 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 84:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:51:31 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:51:43 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:52:00 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 117:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:53:22 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 123:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:53:34 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 151:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:53:49 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 153:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:55:21 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 159:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:55:33 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 181:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:55:49 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 183:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:57:14 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 189:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:57:29 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 208:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:57:51 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 210:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:59:15 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 216:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:59:26 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 231:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 12:59:39 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 233:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:01:08 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 239:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:01:21 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 257:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:01:35 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 259:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:03:03 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 265:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:03:17 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 280:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:03:31 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 282:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:05:02 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 288:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:05:15 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 303:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:05:28 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 305:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:07:33 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 311:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:07:47 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 329:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:08:01 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 331:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:25:36 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 337:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:25:47 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 352:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:26:00 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 354:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:49:46 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 360:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:49:59 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 378:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:50:12 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 380:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:51:31 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 386:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:51:44 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 404:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:51:56 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 406:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:53:14 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 412:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:53:26 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 427:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:53:38 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 429:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:54:56 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 435:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:55:09 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 450:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:55:22 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 452:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:56:41 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 458:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:56:53 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 476:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:57:06 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 478:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:58:25 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 484:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:58:37 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 499:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 13:58:49 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 501:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:00:09 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 507:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:00:21 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 522:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:00:34 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 524:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:01:55 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 530:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:02:07 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 545:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:02:19 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 547:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:03:38 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 553:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:03:50 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 568:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:04:03 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 570:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:05:21 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 576:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:05:33 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 598:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:05:47 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 600:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:07:07 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 606:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:07:22 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 625:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:07:39 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 627:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:09:04 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 633:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:09:16 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 655:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:09:31 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 657:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:10:55 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 663:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:11:08 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 682:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:11:24 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 684:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:12:52 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 690:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:13:04 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 705:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:13:18 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 707:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:14:37 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 713:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:14:55 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 732:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:15:17 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 734:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:16:55 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 740:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:17:07 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 759:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:17:21 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 761:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:19:06 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 767:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:19:21 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 786:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:19:39 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 788:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:21:22 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 794:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:21:36 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 813:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:21:53 WARN MemoryStore: Not enough space to cache rdd_79_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    }
   ],
   "source": [
    "profile = spark_df_profiling.ProfileReport(df_sample)\n",
    "profile.to_file(outputfile=\"../data/profile-report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv_dev_trial-spark-local-pandas-api': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0ab8a3482c3f6df50192c74b784e4b117f25eb61f184ff3f21cd0b626f7656a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
