{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "from pyspark.sql import SparkSession\n",
    "import spark_df_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 23:34:33 WARN Utils: Your hostname, tmps-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.62 instead (on interface en0)\n",
      "22/09/26 23:34:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 23:34:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "session = SparkSession.builder.getOrCreate()\n",
    "ipsc = ibis.pyspark.connect(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/Users/mjboothaus/code/github/mjboothaus/sparky/notebooks/spark-warehouse'),\n",
       " ('spark.driver.port', '55193'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.id', 'local-1664199275837'),\n",
       " ('spark.app.name', 'pyspark-shell'),\n",
       " ('spark.driver.host', 'tmps-air'),\n",
       " ('spark.app.startTime', '1664199274404'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.submitTime', '1664199274206'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sparkContext._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df_rdd = session.read.csv(\"../data/sample_big_mortgage_file.csv.gz\", header=True, sep=\"|\")\n",
    "\n",
    "df_rdd = session.read.csv(\"../data/2020_lar.txt.gz\", header=True, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 23:34:43 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "# Try making dataframe a table and query with SQL\n",
    "\n",
    "df_rdd.createTempView(\"tmp_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ibis.backends.pyspark.Backend at 0x1474e92b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.list_databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tmp_df_table']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.list_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table = ipsc.table(\"tmp_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derived_msa_md\n",
      "derived_loan_product_type\n",
      "derived_dwelling_category\n",
      "derived_ethnicity\n",
      "derived_race\n",
      "derived_sex\n",
      "discount_points\n",
      "debt_to_income_ratio\n",
      "denial_reason_1\n",
      "denial_reason_2\n",
      "denial_reason_3\n",
      "denial_reason_4\n"
     ]
    }
   ],
   "source": [
    "for col in my_table.columns:\n",
    "    if col[0] == \"d\":\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM tmp_df_table LIMIT 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT DISTINCT derived_sex FROM tmp_df_table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = session.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      derived_sex|\n",
      "+-----------------+\n",
      "|Sex Not Available|\n",
      "|           Female|\n",
      "|            Joint|\n",
      "|             Male|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now the Ibis approach\n",
    "\n",
    "ibis.options.interactive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.current_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/zhl433ms1fx5rvtvcrkw6dgw0000gn/T/ipykernel_7939/3364586496.py:1: FutureWarning: `exists_table` is deprecated as of v2.0; use `name in client.list_tables()`\n",
      "  ipsc.exists_table(\"tmp_df_table\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.exists_table(\"tmp_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activity_year',\n",
       " 'lei',\n",
       " 'derived_msa_md',\n",
       " 'state_code',\n",
       " 'county_code',\n",
       " 'census_tract',\n",
       " 'conforming_loan_limit',\n",
       " 'derived_loan_product_type',\n",
       " 'derived_dwelling_category',\n",
       " 'derived_ethnicity',\n",
       " 'derived_race',\n",
       " 'derived_sex',\n",
       " 'action_taken',\n",
       " 'purchaser_type',\n",
       " 'preapproval',\n",
       " 'loan_type',\n",
       " 'loan_purpose',\n",
       " 'lien_status',\n",
       " 'reverse_mortgage',\n",
       " 'open_end_line_of_credit',\n",
       " 'business_or_commercial_purpose',\n",
       " 'loan_amount',\n",
       " 'combined_loan_to_value_ratio',\n",
       " 'interest_rate',\n",
       " 'rate_spread',\n",
       " 'hoepa_status',\n",
       " 'total_loan_costs',\n",
       " 'total_points_and_fees',\n",
       " 'origination_charges',\n",
       " 'discount_points',\n",
       " 'lender_credits',\n",
       " 'loan_term',\n",
       " 'prepayment_penalty_term',\n",
       " 'intro_rate_period',\n",
       " 'negative_amortization',\n",
       " 'interest_only_payment',\n",
       " 'balloon_payment',\n",
       " 'other_nonamortizing_features',\n",
       " 'property_value',\n",
       " 'construction_method',\n",
       " 'occupancy_type',\n",
       " 'manufactured_home_secured_property_type',\n",
       " 'manufactured_home_land_property_interest',\n",
       " 'total_units',\n",
       " 'multifamily_affordable_units',\n",
       " 'income',\n",
       " 'debt_to_income_ratio',\n",
       " 'applicant_credit_score_type',\n",
       " 'co_applicant_credit_score_type',\n",
       " 'applicant_ethnicity_1',\n",
       " 'applicant_ethnicity_2',\n",
       " 'applicant_ethnicity_3',\n",
       " 'applicant_ethnicity_4',\n",
       " 'applicant_ethnicity_5',\n",
       " 'co_applicant_ethnicity_1',\n",
       " 'co_applicant_ethnicity_2',\n",
       " 'co_applicant_ethnicity_3',\n",
       " 'co_applicant_ethnicity_4',\n",
       " 'co_applicant_ethnicity_5',\n",
       " 'applicant_ethnicity_observed',\n",
       " 'co_applicant_ethnicity_observed',\n",
       " 'applicant_race_1',\n",
       " 'applicant_race_2',\n",
       " 'applicant_race_3',\n",
       " 'applicant_race_4',\n",
       " 'applicant_race_5',\n",
       " 'co_applicant_race_1',\n",
       " 'co_applicant_race_2',\n",
       " 'co_applicant_race_3',\n",
       " 'co_applicant_race_4',\n",
       " 'co_applicant_race_5',\n",
       " 'applicant_race_observed',\n",
       " 'co_applicant_race_observed',\n",
       " 'applicant_sex',\n",
       " 'co_applicant_sex',\n",
       " 'applicant_sex_observed',\n",
       " 'co_applicant_sex_observed',\n",
       " 'applicant_age',\n",
       " 'co_applicant_age',\n",
       " 'applicant_age_above_62',\n",
       " 'co_applicant_age_above_62',\n",
       " 'submission_of_application',\n",
       " 'initially_payable_to_institution',\n",
       " 'aus_1',\n",
       " 'aus_2',\n",
       " 'aus_3',\n",
       " 'aus_4',\n",
       " 'aus_5',\n",
       " 'denial_reason_1',\n",
       " 'denial_reason_2',\n",
       " 'denial_reason_3',\n",
       " 'denial_reason_4',\n",
       " 'tract_population',\n",
       " 'tract_minority_population_percent',\n",
       " 'ffiec_msa_md_median_family_income',\n",
       " 'tract_to_msa_income_percentage',\n",
       " 'tract_owner_occupied_units',\n",
       " 'tract_one_to_four_family_homes',\n",
       " 'tract_median_age_of_housing_units']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsc.table(\"tmp_df_table\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ipsc.table(\"tmp_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = t.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibis.show_sql(expr) <<--- this doesn't seem to work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample = df_rdd.sample(fraction=0.1, seed=42).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 23:35:55 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[activity_year: string, lei: string, derived_msa_md: string, state_code: string, county_code: string, census_tract: string, conforming_loan_limit: string, derived_loan_product_type: string, derived_dwelling_category: string, derived_ethnicity: string, derived_race: string, derived_sex: string, action_taken: string, purchaser_type: string, preapproval: string, loan_type: string, loan_purpose: string, lien_status: string, reverse_mortgage: string, open_end_line_of_credit: string, business_or_commercial_purpose: string, loan_amount: string, combined_loan_to_value_ratio: string, interest_rate: string, rate_spread: string, hoepa_status: string, total_loan_costs: string, total_points_and_fees: string, origination_charges: string, discount_points: string, lender_credits: string, loan_term: string, prepayment_penalty_term: string, intro_rate_period: string, negative_amortization: string, interest_only_payment: string, balloon_payment: string, other_nonamortizing_features: string, property_value: string, construction_method: string, occupancy_type: string, manufactured_home_secured_property_type: string, manufactured_home_land_property_interest: string, total_units: string, multifamily_affordable_units: string, income: string, debt_to_income_ratio: string, applicant_credit_score_type: string, co_applicant_credit_score_type: string, applicant_ethnicity_1: string, applicant_ethnicity_2: string, applicant_ethnicity_3: string, applicant_ethnicity_4: string, applicant_ethnicity_5: string, co_applicant_ethnicity_1: string, co_applicant_ethnicity_2: string, co_applicant_ethnicity_3: string, co_applicant_ethnicity_4: string, co_applicant_ethnicity_5: string, applicant_ethnicity_observed: string, co_applicant_ethnicity_observed: string, applicant_race_1: string, applicant_race_2: string, applicant_race_3: string, applicant_race_4: string, applicant_race_5: string, co_applicant_race_1: string, co_applicant_race_2: string, co_applicant_race_3: string, co_applicant_race_4: string, co_applicant_race_5: string, applicant_race_observed: string, co_applicant_race_observed: string, applicant_sex: string, co_applicant_sex: string, applicant_sex_observed: string, co_applicant_sex_observed: string, applicant_age: string, co_applicant_age: string, applicant_age_above_62: string, co_applicant_age_above_62: string, submission_of_application: string, initially_payable_to_institution: string, aus_1: string, aus_2: string, aus_3: string, aus_4: string, aus_5: string, denial_reason_1: string, denial_reason_2: string, denial_reason_3: string, denial_reason_4: string, tract_population: string, tract_minority_population_percent: string, ffiec_msa_md_median_family_income: string, tract_to_msa_income_percentage: string, tract_owner_occupied_units: string, tract_one_to_four_family_homes: string, tract_median_age_of_housing_units: string]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rdd_cache = df_rdd.cache()\n",
    "df_rdd_cache.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 23:36:29 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n",
      "22/09/26 23:36:29 WARN BlockManager: Persisting block rdd_32_0 to disk instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 00:20:12 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 00:20:16 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 00:20:37 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 00:21:02 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:408: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_constant_1d(df, column))\n",
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 00:21:05 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 00:36:38 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 00:37:17 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 48:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 01:20:31 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 01:36:36 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 01:37:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 81:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 01:55:15 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 01:55:43 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 01:56:12 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 117:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 01:59:36 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 123:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:00:05 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 145:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:00:40 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 147:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:04:16 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 153:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:04:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 172:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:05:40 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 174:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:09:06 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 180:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:09:32 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 195:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:09:58 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 197:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:13:32 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 203:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:13:59 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 221:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:14:31 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 223:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:18:04 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 229:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:18:34 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 244:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:19:04 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 246:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:22:52 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 252:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:23:21 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 267:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:23:51 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 269:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:27:42 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 275:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:28:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 293:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:28:37 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 295:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:32:28 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 301:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:32:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 316:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:33:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 318:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:37:14 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 324:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:37:38 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 342:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:38:01 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 344:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:41:23 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 350:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:41:48 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 368:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:42:12 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 370:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:45:32 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 376:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:45:55 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 391:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:46:20 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 393:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:49:41 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 399:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:50:05 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 414:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 02:50:29 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 416:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 03:10:10 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 422:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 03:10:37 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 440:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 03:11:07 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 442:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 03:49:58 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 448:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:00:12 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 463:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:00:38 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 465:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:03:55 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 471:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:04:20 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 486:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:04:46 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 488:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:08:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 494:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:08:35 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 509:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:09:02 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 511:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:12:23 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 517:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:12:48 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 532:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:13:15 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 534:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:16:22 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 540:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:16:51 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 562:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:17:21 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 564:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:20:30 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 570:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:21:03 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 589:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:21:45 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 591:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:25:07 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 597:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:25:33 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 619:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:26:03 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 621:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:29:35 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 627:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:30:02 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 646:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:30:34 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 648:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:34:10 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 654:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:34:36 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 669:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:35:00 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 671:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:38:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 677:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:39:00 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 696:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:39:41 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 698:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:43:20 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 704:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:43:44 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 723:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:44:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 725:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:48:06 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 731:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:48:39 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 750:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:49:14 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 752:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:52:56 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 758:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:53:26 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 777:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:53:57 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 779:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:56:25 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 785:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:56:54 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 804:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:57:26 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 806:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 04:59:58 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 812:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:12:13 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 837:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:12:42 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 839:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:16:16 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 845:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:16:42 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 873:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:17:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 875:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:20:57 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 881:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:21:22 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 909:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:21:50 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 911:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:25:24 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 917:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:25:48 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 932:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:26:15 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 934:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:29:23 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 940:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:29:48 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 955:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:30:15 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 957:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:33:33 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 963:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:33:56 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 978:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:34:24 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 980:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:37:40 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 986:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:38:07 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1001:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:38:32 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1003:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:41:50 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1009:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:42:18 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1031:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:42:45 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1033:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:46:21 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1039:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:46:43 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1054:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:47:08 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1056:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:50:30 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1062:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:50:52 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1077:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:51:18 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1079:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:54:39 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1085:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:55:02 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1100:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:55:25 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1102:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:58:49 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1108:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:59:11 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1126:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 05:59:33 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1128:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:02:55 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1134:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:03:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1152:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:03:41 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1154:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:07:05 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1160:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:07:29 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1188:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:07:52 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1190:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:11:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1196:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:12:17 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1215:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:12:42 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1217:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:16:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1223:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:16:47 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1241:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:17:16 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1241:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:20:45 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 173291 ms exceeds timeout 120000 ms\n",
      "22/09/27 06:20:45 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1243:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:24:03 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1249:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:24:29 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1267:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:24:57 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1269:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:28:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1275:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:28:32 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1293:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:28:54 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1295:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:32:21 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1301:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:32:44 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1319:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:33:07 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1321:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:36:31 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1327:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:36:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1345:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:37:15 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1347:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:37:36 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1353:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:37:58 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1371:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:38:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1373:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:38:36 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1379:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:38:58 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1397:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:39:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1399:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:39:38 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1405:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:40:00 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1420:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:40:22 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1422:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:40:41 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1428:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:41:04 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1446:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:41:27 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1448:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:44:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1454:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:45:16 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1472:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:45:36 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1474:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:45:57 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1480:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:46:18 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1498:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:46:38 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1500:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:46:57 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1506:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:47:18 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1521:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:47:38 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1523:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:47:57 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1529:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:48:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1544:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:48:39 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1546:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:48:58 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1552:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:49:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1567:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:49:41 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1569:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:53:07 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1575:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:53:30 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1590:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:53:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1592:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:57:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1598:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:57:41 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1616:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 06:58:05 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1618:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:01:28 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1624:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:01:50 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1642:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:02:11 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1644:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:02:32 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1650:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:02:54 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1668:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:03:14 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1670:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:03:33 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1676:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:03:55 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1694:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:04:16 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1696:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:04:34 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1702:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:04:55 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1720:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:05:16 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1722:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:05:34 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1728:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:05:56 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1746:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:06:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1748:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:09:42 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1754:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:10:07 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1772:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:10:28 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1774:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:10:48 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1780:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:11:11 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1798:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:11:31 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1800:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:11:50 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1806:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:12:12 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1824:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:12:33 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1826:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:12:52 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1832:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:13:13 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1850:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:13:33 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1852:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:13:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1858:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:14:15 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1873:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:14:36 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1875:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:18:03 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1881:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:18:27 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1896:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:18:50 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1898:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:22:15 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1904:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:22:37 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1919:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:23:00 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1921:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:33:18 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1927:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:33:45 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1945:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:34:13 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1947:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:37:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1953:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:37:42 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1968:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:38:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1970:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:41:18 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1976:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:41:40 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1991:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:42:04 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 1993:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:45:26 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1999:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:45:50 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2017:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:46:16 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2019:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:50:24 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2025:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:50:46 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2043:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:51:10 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2045:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:55:02 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2051:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:55:24 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2066:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:55:47 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2068:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:58:15 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2074:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:58:26 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2089:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 07:58:37 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2091:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:00:07 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2097:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:00:18 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2112:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:00:29 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2114:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:01:47 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2120:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:01:57 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2135:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:02:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2137:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:03:27 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2143:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:03:38 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2161:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:03:49 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2163:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:05:08 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2169:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:05:19 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2184:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:05:29 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2186:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:05:41 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2192:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:05:52 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2207:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:06:02 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2209:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:06:12 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2215:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:06:22 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2230:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:06:32 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2232:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:06:42 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2238:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:06:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2253:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:07:02 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2255:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:07:12 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2261:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:07:23 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2279:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:07:34 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2281:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:08:54 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2287:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:09:04 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2305:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:09:14 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2307:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:09:24 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2313:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:09:35 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2331:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:09:45 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2333:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:09:54 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2339:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:10:04 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2357:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:10:14 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2359:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:10:23 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2365:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:10:35 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2387:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:10:48 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2389:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:12:08 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2395:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:12:21 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2414:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:12:36 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2416:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:13:58 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2422:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:14:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2450:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:14:22 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2452:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:15:42 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2458:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:15:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2486:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:16:05 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2488:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:44:48 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2494:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:45:15 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2516:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 08:45:42 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2518:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 09:16:50 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2524:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 09:33:37 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2546:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 09:34:09 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n",
      "[Stage 2548:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 10:12:28 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2554:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 10:12:39 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2582:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/27 10:12:51 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 286.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/sparky/.venv_dev_trial-spark-local-pandas-api/lib/python3.9/site-packages/spark_df_profiling/base.py:418: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(describe_categorical_1d(df, column))\n"
     ]
    }
   ],
   "source": [
    "profile = spark_df_profiling.ProfileReport(df_rdd_cache)\n",
    "profile.to_file(outputfile=\"../data/profile-report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv_dev_trial-spark-local-pandas-api': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0ab8a3482c3f6df50192c74b784e4b117f25eb61f184ff3f21cd0b626f7656a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
